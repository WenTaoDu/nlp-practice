{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition-based arc-eager unlabeled dependency parser for Ukrainian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "Useful links:\n",
    "* [UD corpus for Ukrainian](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
    "* [Easy-to-use library for parsing UD](https://github.com/EmilStenstrom/conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install wget conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from os.path import join, isfile, isdir\n",
    "from os import mkdir\n",
    "from random import Random\n",
    "from typing import List, Dict\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from conllu import parse, TokenList\n",
    "\n",
    "_url_prefix = \"https://github.com/UniversalDependencies/UD_Ukrainian-IU/blob/master/\"\n",
    "DEV_FILENAME = \"uk_iu-ud-dev.conllu\"\n",
    "TEST_FILENAME = \"uk_iu-ud-test.conllu\"\n",
    "TRAIN_FILENAME = \"uk_iu-ud-train.conllu\"\n",
    "\n",
    "_PATH = \"data/\"\n",
    "\n",
    "_rnd = Random(1974)\n",
    "\n",
    "\n",
    "def load_trees(filename: str) -> List[TokenList]:\n",
    "    if not isdir(_PATH):\n",
    "        mkdir(_PATH)\n",
    "\n",
    "    full_name = join(_PATH, filename)\n",
    "    if not isfile(full_name):\n",
    "        wget.download(_url_prefix + filename + '?raw=true', full_name)\n",
    "\n",
    "    with open(full_name, \"r\", encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    result = parse(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set contains 11899 tokens in 647 sentences\n",
      "Test set contains 16293 tokens in 864 sentences\n",
      "Train set contains 88252 tokens in 5290 sentences\n",
      "OrderedDict([('id', 1), ('form', 'У'), ('lemma', 'у'), ('upostag', 'ADP'), ('xpostag', 'Spsl'), ('feats', OrderedDict([('Case', 'Loc')])), ('head', 2), ('deprel', 'case'), ('deps', [('case', 2)]), ('misc', OrderedDict([('Id', '0003'), ('LTranslit', 'u'), ('Translit', 'U')]))])\n",
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "trees = load_trees(DEV_FILENAME)\n",
    "tokens = sum(len(tree) for tree in trees)\n",
    "print(f\"Dev set contains {tokens} tokens in {len(trees)} sentences\")\n",
    "trees = load_trees(TEST_FILENAME)\n",
    "tokens = sum(len(tree) for tree in trees)\n",
    "print(f\"Test set contains {tokens} tokens in {len(trees)} sentences\")\n",
    "trees = load_trees(TRAIN_FILENAME)\n",
    "tokens = sum(len(tree) for tree in trees)\n",
    "print(f\"Train set contains {tokens} tokens in {len(trees)} sentences\")\n",
    "tree = trees[0]\n",
    "print(tree[0])\n",
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                         tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', 1), ('form', 'У'), ('lemma', 'у'), ('upostag', 'ADP'), ('xpostag', 'Spsl'), ('feats', OrderedDict([('Case', 'Loc')])), ('head', 2), ('deprel', 'case'), ('deps', [('case', 2)]), ('misc', OrderedDict([('Id', '0003'), ('LTranslit', 'u'), ('Translit', 'U')]))])\n"
     ]
    }
   ],
   "source": [
    "tree = trees[0]\n",
    "print(tree[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design actions and the oracle\n",
    "\n",
    "We will be using a static oracle that reproduces a single valid order of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack: ['ROOT_0']\n",
      "Queue: ['У_1', 'домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: []\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'У_1']\n",
      "Queue: ['домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: []\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: ['домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'римського_3']\n",
      "Queue: ['патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4']\n",
      "Queue: ['Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4', 'Руфіна_5']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'прегарна_7']\n",
      "Queue: ['фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: [',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', ',_9']\n",
      "Queue: ['зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: ['зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10']\n",
      "Queue: ['Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11', 'та_12']\n",
      "Queue: ['Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11', 'Адоніса_13']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', '._14']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Gold relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Retrieved relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n"
     ]
    }
   ],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))\n",
    "\n",
    "trace_actions(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Reference: [Dependency Parsing by Kübler, McDonald, and Nivre](https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA21&hl=uk&source=gbs_toc_r&cad=4#v=onepage&q&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        if stack_top[\"feats\"]:\n",
    "            for k, v in stack_top[\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack_top[\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        if queue_top[\"feats\"]:\n",
    "            for k, v in queue_top[\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    if stack and queue:\n",
    "        features[\"distance\"] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 14\n",
      "Number of actions: 29\n",
      "List of actions taken: ['shift', 'left', 'shift', 'shift', 'left', 'right', 'right', 'reduce', 'reduce', 'left', 'right', 'shift', 'left', 'right', 'shift', 'left', 'right', 'right', 'shift', 'left', 'right', 'reduce', 'reduce', 'reduce', 'reduce', 'right', 'reduce', 'reduce', 'reduce']\n",
      "Features:\n",
      "{'s0-word': 'ROOT', 's0-lemma': 'ROOT', 's0-tag': 'ROOT', 'q0-word': 'У', 'q0-lemma': 'у', 'q0-tag': 'ADP', 'q0-Case': 'Loc', 'q1-word': 'домі', 'q1-tag': 'NOUN', 'q2-tag': 'ADJ', 'q3-tag': 'NOUN', 'distance': 1}\n",
      "{'s0-word': 'У', 's0-lemma': 'у', 's0-tag': 'ADP', 's0-Case': 'Loc', 's1-tag': 'ADP', 'q0-word': 'домі', 'q0-lemma': 'дім', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Loc', 'q0-Gender': 'Masc', 'q0-Number': 'Sing', 'q1-word': 'римського', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PROPN', 'distance': 1}\n",
      "{'s0-word': 'ROOT', 's0-lemma': 'ROOT', 's0-tag': 'ROOT', 'q0-word': 'домі', 'q0-lemma': 'дім', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Loc', 'q0-Gender': 'Masc', 'q0-Number': 'Sing', 'q1-word': 'римського', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PROPN', 'distance': 2}\n",
      "{'s0-word': 'домі', 's0-lemma': 'дім', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Loc', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'римського', 'q0-lemma': 'римський', 'q0-tag': 'ADJ', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-Number': 'Sing', 'q1-word': 'патриція', 'q1-tag': 'NOUN', 'q2-tag': 'PROPN', 'q3-tag': 'VERB', 'distance': 1}\n",
      "{'s0-word': 'римського', 's0-lemma': 'римський', 's0-tag': 'ADJ', 's0-Case': 'Gen', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'ADJ', 'q0-word': 'патриція', 'q0-lemma': 'патрицій', 'q0-tag': 'NOUN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-Number': 'Sing', 'q1-word': 'Руфіна', 'q1-tag': 'PROPN', 'q2-tag': 'VERB', 'q3-tag': 'ADJ', 'distance': 1}\n",
      "{'s0-word': 'домі', 's0-lemma': 'дім', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Loc', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'патриція', 'q0-lemma': 'патрицій', 'q0-tag': 'NOUN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-Number': 'Sing', 'q1-word': 'Руфіна', 'q1-tag': 'PROPN', 'q2-tag': 'VERB', 'q3-tag': 'ADJ', 'distance': 2}\n",
      "{'s0-word': 'патриція', 's0-lemma': 'патрицій', 's0-tag': 'NOUN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'Руфіна', 'q0-lemma': 'Руфін', 'q0-tag': 'PROPN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-NameType': 'Giv', 'q0-Number': 'Sing', 'q1-word': 'була', 'q1-tag': 'VERB', 'q2-tag': 'ADJ', 'q3-tag': 'NOUN', 'distance': 1}\n",
      "{'s0-word': 'Руфіна', 's0-lemma': 'Руфін', 's0-tag': 'PROPN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Masc', 's0-NameType': 'Giv', 's0-Number': 'Sing', 's1-tag': 'PROPN', 'q0-word': 'була', 'q0-lemma': 'бути', 'q0-tag': 'VERB', 'q0-Aspect': 'Imp', 'q0-Gender': 'Fem', 'q0-Mood': 'Ind', 'q0-Number': 'Sing', 'q0-Tense': 'Past', 'q0-VerbForm': 'Fin', 'q1-word': 'прегарна', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PUNCT', 'distance': 1}\n",
      "{'s0-word': 'патриція', 's0-lemma': 'патрицій', 's0-tag': 'NOUN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'була', 'q0-lemma': 'бути', 'q0-tag': 'VERB', 'q0-Aspect': 'Imp', 'q0-Gender': 'Fem', 'q0-Mood': 'Ind', 'q0-Number': 'Sing', 'q0-Tense': 'Past', 'q0-VerbForm': 'Fin', 'q1-word': 'прегарна', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PUNCT', 'distance': 2}\n",
      "{'s0-word': 'домі', 's0-lemma': 'дім', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Loc', 's0-Gender': 'Masc', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'була', 'q0-lemma': 'бути', 'q0-tag': 'VERB', 'q0-Aspect': 'Imp', 'q0-Gender': 'Fem', 'q0-Mood': 'Ind', 'q0-Number': 'Sing', 'q0-Tense': 'Past', 'q0-VerbForm': 'Fin', 'q1-word': 'прегарна', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PUNCT', 'distance': 4}\n",
      "{'s0-word': 'ROOT', 's0-lemma': 'ROOT', 's0-tag': 'ROOT', 'q0-word': 'була', 'q0-lemma': 'бути', 'q0-tag': 'VERB', 'q0-Aspect': 'Imp', 'q0-Gender': 'Fem', 'q0-Mood': 'Ind', 'q0-Number': 'Sing', 'q0-Tense': 'Past', 'q0-VerbForm': 'Fin', 'q1-word': 'прегарна', 'q1-tag': 'ADJ', 'q2-tag': 'NOUN', 'q3-tag': 'PUNCT', 'distance': 6}\n",
      "{'s0-word': 'була', 's0-lemma': 'бути', 's0-tag': 'VERB', 's0-Aspect': 'Imp', 's0-Gender': 'Fem', 's0-Mood': 'Ind', 's0-Number': 'Sing', 's0-Tense': 'Past', 's0-VerbForm': 'Fin', 's1-tag': 'VERB', 'q0-word': 'прегарна', 'q0-lemma': 'прегарний', 'q0-tag': 'ADJ', 'q0-Case': 'Nom', 'q0-Gender': 'Fem', 'q0-Number': 'Sing', 'q1-word': 'фреска', 'q1-tag': 'NOUN', 'q2-tag': 'PUNCT', 'q3-tag': 'NOUN', 'distance': 1}\n",
      "{'s0-word': 'прегарна', 's0-lemma': 'прегарний', 's0-tag': 'ADJ', 's0-Case': 'Nom', 's0-Gender': 'Fem', 's0-Number': 'Sing', 's1-tag': 'ADJ', 'q0-word': 'фреска', 'q0-lemma': 'фреска', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Nom', 'q0-Gender': 'Fem', 'q0-Number': 'Sing', 'q1-word': ',', 'q1-tag': 'PUNCT', 'q2-tag': 'NOUN', 'q3-tag': 'PROPN', 'distance': 1}\n",
      "{'s0-word': 'була', 's0-lemma': 'бути', 's0-tag': 'VERB', 's0-Aspect': 'Imp', 's0-Gender': 'Fem', 's0-Mood': 'Ind', 's0-Number': 'Sing', 's0-Tense': 'Past', 's0-VerbForm': 'Fin', 's1-tag': 'VERB', 'q0-word': 'фреска', 'q0-lemma': 'фреска', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Nom', 'q0-Gender': 'Fem', 'q0-Number': 'Sing', 'q1-word': ',', 'q1-tag': 'PUNCT', 'q2-tag': 'NOUN', 'q3-tag': 'PROPN', 'distance': 2}\n",
      "{'s0-word': 'фреска', 's0-lemma': 'фреска', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Nom', 's0-Gender': 'Fem', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': ',', 'q0-lemma': ',', 'q0-tag': 'PUNCT', 'q1-word': 'зображення', 'q1-tag': 'NOUN', 'q2-tag': 'PROPN', 'q3-tag': 'CCONJ', 'distance': 1}\n",
      "{'s0-word': ',', 's0-lemma': ',', 's0-tag': 'PUNCT', 's1-tag': 'PUNCT', 'q0-word': 'зображення', 'q0-lemma': 'зображення', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Nom', 'q0-Gender': 'Neut', 'q0-Number': 'Sing', 'q1-word': 'Венери', 'q1-tag': 'PROPN', 'q2-tag': 'CCONJ', 'q3-tag': 'PROPN', 'distance': 1}\n",
      "{'s0-word': 'фреска', 's0-lemma': 'фреска', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Nom', 's0-Gender': 'Fem', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'зображення', 'q0-lemma': 'зображення', 'q0-tag': 'NOUN', 'q0-Animacy': 'Inan', 'q0-Case': 'Nom', 'q0-Gender': 'Neut', 'q0-Number': 'Sing', 'q1-word': 'Венери', 'q1-tag': 'PROPN', 'q2-tag': 'CCONJ', 'q3-tag': 'PROPN', 'distance': 2}\n",
      "{'s0-word': 'зображення', 's0-lemma': 'зображення', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Nom', 's0-Gender': 'Neut', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': 'Венери', 'q0-lemma': 'Венера', 'q0-tag': 'PROPN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Fem', 'q0-NameType': 'Giv', 'q0-Number': 'Sing', 'q1-word': 'та', 'q1-tag': 'CCONJ', 'q2-tag': 'PROPN', 'q3-tag': 'PUNCT', 'distance': 1}\n",
      "{'s0-word': 'Венери', 's0-lemma': 'Венера', 's0-tag': 'PROPN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Fem', 's0-NameType': 'Giv', 's0-Number': 'Sing', 's1-tag': 'PROPN', 'q0-word': 'та', 'q0-lemma': 'та', 'q0-tag': 'CCONJ', 'q1-word': 'Адоніса', 'q1-tag': 'PROPN', 'q2-tag': 'PUNCT', 'distance': 1}\n",
      "{'s0-word': 'та', 's0-lemma': 'та', 's0-tag': 'CCONJ', 's1-tag': 'CCONJ', 'q0-word': 'Адоніса', 'q0-lemma': 'Адоніс', 'q0-tag': 'PROPN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-NameType': 'Giv', 'q0-Number': 'Sing', 'q1-word': '.', 'q1-tag': 'PUNCT', 'distance': 1}\n",
      "{'s0-word': 'Венери', 's0-lemma': 'Венера', 's0-tag': 'PROPN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Fem', 's0-NameType': 'Giv', 's0-Number': 'Sing', 's1-tag': 'PROPN', 'q0-word': 'Адоніса', 'q0-lemma': 'Адоніс', 'q0-tag': 'PROPN', 'q0-Animacy': 'Anim', 'q0-Case': 'Gen', 'q0-Gender': 'Masc', 'q0-NameType': 'Giv', 'q0-Number': 'Sing', 'q1-word': '.', 'q1-tag': 'PUNCT', 'distance': 2}\n",
      "{'s0-word': 'Адоніса', 's0-lemma': 'Адоніс', 's0-tag': 'PROPN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Masc', 's0-NameType': 'Giv', 's0-Number': 'Sing', 's1-tag': 'PROPN', 'q0-word': '.', 'q0-lemma': '.', 'q0-tag': 'PUNCT', 'distance': 1}\n",
      "{'s0-word': 'Венери', 's0-lemma': 'Венера', 's0-tag': 'PROPN', 's0-Animacy': 'Anim', 's0-Case': 'Gen', 's0-Gender': 'Fem', 's0-NameType': 'Giv', 's0-Number': 'Sing', 's1-tag': 'PROPN', 'q0-word': '.', 'q0-lemma': '.', 'q0-tag': 'PUNCT', 'distance': 3}\n",
      "{'s0-word': 'зображення', 's0-lemma': 'зображення', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Nom', 's0-Gender': 'Neut', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': '.', 'q0-lemma': '.', 'q0-tag': 'PUNCT', 'distance': 4}\n",
      "{'s0-word': 'фреска', 's0-lemma': 'фреска', 's0-tag': 'NOUN', 's0-Animacy': 'Inan', 's0-Case': 'Nom', 's0-Gender': 'Fem', 's0-Number': 'Sing', 's1-tag': 'NOUN', 'q0-word': '.', 'q0-lemma': '.', 'q0-tag': 'PUNCT', 'distance': 6}\n",
      "{'s0-word': 'була', 's0-lemma': 'бути', 's0-tag': 'VERB', 's0-Aspect': 'Imp', 's0-Gender': 'Fem', 's0-Mood': 'Ind', 's0-Number': 'Sing', 's0-Tense': 'Past', 's0-VerbForm': 'Fin', 's1-tag': 'VERB', 'q0-word': '.', 'q0-lemma': '.', 'q0-tag': 'PUNCT', 'distance': 8}\n",
      "{'s0-word': '.', 's0-lemma': '.', 's0-tag': 'PUNCT', 's1-tag': 'PUNCT'}\n",
      "{'s0-word': 'була', 's0-lemma': 'бути', 's0-tag': 'VERB', 's0-Aspect': 'Imp', 's0-Gender': 'Fem', 's0-Mood': 'Ind', 's0-Number': 'Sing', 's0-Tense': 'Past', 's0-VerbForm': 'Fin', 's1-tag': 'VERB'}\n",
      "{'s0-word': 'ROOT', 's0-lemma': 'ROOT', 's0-tag': 'ROOT'}\n"
     ]
    }
   ],
   "source": [
    "features, labels = get_data(tree)\n",
    "print(\"Number of words:\", len(tree))\n",
    "print(\"Number of actions:\", len(labels))\n",
    "print(\"List of actions taken:\", labels)\n",
    "print(\"Features:\")\n",
    "for word in features:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181376 181376\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24423 24423\n"
     ]
    }
   ],
   "source": [
    "# Dev data\n",
    "\n",
    "dev_trees = load_trees(DEV_FILENAME)\n",
    "\n",
    "dev_features, dev_labels = [], []\n",
    "for tree in dev_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    dev_features += tree_features\n",
    "    dev_labels += tree_labels\n",
    "\n",
    "print(len(dev_features), len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33406 33406\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "test_trees = load_trees(TEST_FILENAME)\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  107993\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181376, 107993)\n",
      "(24423, 107993)\n",
      "(33406, 107993)\n"
     ]
    }
   ],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "dev_features_vectorized = vec.transform(dev_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "print(train_features_vectorized.shape)\n",
    "print(dev_features_vectorized.shape)\n",
    "print(test_features_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1997 epochs took 403 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='multinomial',\n",
       "          n_jobs=4, penalty='l2', random_state=42, solver='sag',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=42, n_jobs=4, \n",
    "                         solver=\"sag\", multi_class=\"multinomial\", max_iter=2000, verbose=1)\n",
    "lrc.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.85      0.87      0.86      8222\n",
      "      reduce       0.81      0.72      0.76      8913\n",
      "       right       0.74      0.80      0.77      7897\n",
      "       shift       0.88      0.89      0.88      8374\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     33406\n",
      "   macro avg       0.82      0.82      0.82     33406\n",
      "weighted avg       0.82      0.82      0.82     33406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the unlabeled attachment score\n",
    "UAS - the percentage of words in an input that are assigned the correct head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            if log:\n",
    "                print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "                print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "                print(\"Relations:\", relations)\n",
    "                print(action)\n",
    "                print(\"========================\")\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(f\"Unknown action '{action}'.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 16271\n",
      "Correctly defined: 11520\n",
      "UAS: 0.71\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7206757344642715689\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['right', 'reduce', 'left', 'shift']\n",
      "{'right': 0, 'reduce': 1, 'left': 2, 'shift': 3}\n"
     ]
    }
   ],
   "source": [
    "labels_list = list(set(train_labels))\n",
    "print(labels_list)\n",
    "labels_dict = {name:i for i, name in enumerate(labels_list)}\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_ind(y: np.array)->np.array:\n",
    "    return np.array([labels_dict[name] for name in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_idx = labels_to_ind(train_labels)\n",
    "one_hot_train_labels = to_categorical(train_labels_idx)\n",
    "dev_labels_idx = labels_to_ind(dev_labels)\n",
    "one_hot_dev_labels = to_categorical(dev_labels_idx)\n",
    "test_labels_idx = labels_to_ind(test_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint('data/weights.best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    dim = train_features_vectorized.shape[1]\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', \n",
    "                           kernel_regularizer=regularizers.l1_l2(0.00005, 0.001), \n",
    "                           input_shape=(dim,)))\n",
    "    model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(0.00005, 0.001)))\n",
    "    model.add(layers.Dense(len(labels_dict), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_model()\n",
    "model.compile(optimizer=Adam(lr=0.002),\n",
    "              #optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181376 samples, validate on 24423 samples\n",
      "Epoch 1/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.7060 - acc: 0.8104\n",
      "Epoch 00001: val_acc improved from -inf to 0.83319, saving model to data/weights.best.hdf5\n",
      "181376/181376 [==============================] - 227s 1ms/sample - loss: 0.7060 - acc: 0.8103 - val_loss: 0.6443 - val_acc: 0.8332\n",
      "Epoch 2/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.8427\n",
      "Epoch 00002: val_acc improved from 0.83319 to 0.84175, saving model to data/weights.best.hdf5\n",
      "181376/181376 [==============================] - 227s 1ms/sample - loss: 0.6221 - acc: 0.8426 - val_loss: 0.6187 - val_acc: 0.8417\n",
      "Epoch 3/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.8463\n",
      "Epoch 00003: val_acc improved from 0.84175 to 0.84596, saving model to data/weights.best.hdf5\n",
      "181376/181376 [==============================] - 226s 1ms/sample - loss: 0.6070 - acc: 0.8463 - val_loss: 0.6123 - val_acc: 0.8460\n",
      "Epoch 4/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5994 - acc: 0.8485\n",
      "Epoch 00004: val_acc did not improve from 0.84596\n",
      "181376/181376 [==============================] - 226s 1ms/sample - loss: 0.5994 - acc: 0.8485 - val_loss: 0.6119 - val_acc: 0.8418\n",
      "Epoch 5/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.8499\n",
      "Epoch 00005: val_acc did not improve from 0.84596\n",
      "181376/181376 [==============================] - 227s 1ms/sample - loss: 0.5926 - acc: 0.8500 - val_loss: 0.6019 - val_acc: 0.8447\n",
      "Epoch 6/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5857 - acc: 0.8513\n",
      "Epoch 00006: val_acc improved from 0.84596 to 0.84695, saving model to data/weights.best.hdf5\n",
      "181376/181376 [==============================] - 230s 1ms/sample - loss: 0.5858 - acc: 0.8513 - val_loss: 0.5997 - val_acc: 0.8469\n",
      "Epoch 7/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5823 - acc: 0.8521\n",
      "Epoch 00007: val_acc improved from 0.84695 to 0.85043, saving model to data/weights.best.hdf5\n",
      "181376/181376 [==============================] - 231s 1ms/sample - loss: 0.5824 - acc: 0.8520 - val_loss: 0.5880 - val_acc: 0.8504\n",
      "Epoch 8/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.8524\n",
      "Epoch 00008: val_acc did not improve from 0.85043\n",
      "181376/181376 [==============================] - 234s 1ms/sample - loss: 0.5796 - acc: 0.8524 - val_loss: 0.5890 - val_acc: 0.8491\n",
      "Epoch 9/100\n",
      "181248/181376 [============================>.] - ETA: 0s - loss: 0.5740 - acc: 0.8528"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_features_vectorized,\n",
    "            one_hot_train_labels,\n",
    "            epochs=100,\n",
    "            batch_size=256,\n",
    "            validation_data=(dev_features_vectorized, one_hot_dev_labels),\n",
    "            callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_model()\n",
    "model.load_weights(\"data/weights.best.hdf5\")\n",
    "model.compile(optimizer=Adam(lr=0.002),\n",
    "              #optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_features_vectorized, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_one_hot = model.predict(test_features_vectorized)\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)\n",
    "print(classification_report(test_labels_idx, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotWrapper:\n",
    "    def __init__(self, oracle):\n",
    "        self._oracle = oracle\n",
    "    \n",
    "    def predict(self, features):\n",
    "        y_pred_one_hot = self._oracle.predict(features)\n",
    "        y_pred = [labels_list[i] for i in np.argmax(y_pred_one_hot, axis=1)]\n",
    "        #print(y_pred, y_pred_one_hot, features[0][:5])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = OneHotWrapper(model)\n",
    "\n",
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, oracle, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
