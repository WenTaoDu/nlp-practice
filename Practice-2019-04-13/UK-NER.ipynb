{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"d:\\\\git-nlp\\\\ner-uk\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tokens and positions of tokens from a file\n",
    "\n",
    "def read_tokens(filename):\n",
    "    tokens = []\n",
    "    pos = 0\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        text = f.read().split(\"\\n\")\n",
    "        for line in text:\n",
    "            if len(line) == 0:\n",
    "                pos += 1\n",
    "            else:\n",
    "                tokens.append((\"<S>\", pos, pos))\n",
    "                for token in line.split(\" \"):\n",
    "                    tokens.append((token, pos, pos + len(token)))\n",
    "                    pos += len(token) + 1\n",
    "                tokens.append((\"</S>\", pos, pos))\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotations and positions of annotations from a file\n",
    "\n",
    "def read_annotations(filename):\n",
    "    anno = []\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            annotations = line.split()\n",
    "            #print(annotations)\n",
    "            anno.append((annotations[1], int(annotations[2]), int(annotations[3])))\n",
    "    return anno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using positions of tokens and annotations, extract a list of token labels\n",
    "def cyr_to_lat(label:str):\n",
    "    res = label.replace('ОРГ', 'ORG').replace('ЛОК', 'LOC').replace('ПЕРС', 'PERS').replace('РІЗН', 'MISC')\n",
    "    return res\n",
    "\n",
    "def extract_labels(anno, tokens):\n",
    "    labels = []\n",
    "    ann_id = 0\n",
    "    for token in tokens:\n",
    "        if ann_id < len(anno):\n",
    "            label, beg, end = anno[ann_id]\n",
    "            label = cyr_to_lat(label)\n",
    "            if token[0] in [\"<S>\", \"</S>\"]:\n",
    "                labels.append(\"--\")\n",
    "            elif token[1] < beg:\n",
    "                labels.append(\"--\")\n",
    "            else:\n",
    "                if token[1] == beg:\n",
    "                    labels.append(\"B-\" + label)\n",
    "                else:\n",
    "                    labels.append(\"I-\" + label)\n",
    "                if token[2] == end:\n",
    "                    ann_id += 1\n",
    "        else:\n",
    "            labels.append(\"--\")    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = read_tokens(PATH + \"data/A_alumni.krok.edu.ua_Prokopenko_Vidrodzhennia_velotreku(5).tok.txt\")\n",
    "anno = read_annotations(PATH + \"data/A_alumni.krok.edu.ua_Prokopenko_Vidrodzhennia_velotreku(5).tok.ann\")\n",
    "labels = extract_labels(anno, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S> --\n",
      "Історія --\n",
      "змін --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "Спільними --\n",
      "зусиллями --\n",
      "влада --\n",
      "та --\n",
      "громадськість --\n",
      "врятували --\n",
      "й --\n",
      "повертають --\n",
      "до --\n",
      "життя --\n",
      "Київський B-ORG\n",
      "велотрек I-ORG\n",
      "</S> --\n",
      "<S> --\n",
      "Київський B-ORG\n",
      "велотрек I-ORG\n",
      "« I-ORG\n",
      "Авангард I-ORG\n",
      "» I-ORG\n",
      "по --\n",
      "вул B-LOC\n",
      ". I-LOC\n",
      "Богдана I-LOC\n",
      "Хмельницького I-LOC\n",
      ", I-LOC\n",
      "58-А I-LOC\n",
      ", --\n",
      "що --\n",
      "збудований --\n",
      "у --\n",
      "1913 --\n",
      "році --\n",
      "за --\n",
      "ініціативи --\n",
      "та --\n",
      "кошти --\n",
      "киян --\n",
      ", --\n",
      "відновлюється --\n",
      "так --\n",
      "само --\n",
      "— --\n",
      "силами --\n",
      "громади --\n",
      "і --\n",
      "без --\n",
      "фінансування --\n",
      "з --\n",
      "бюджету --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "А --\n",
      "за --\n",
      "відчутної --\n",
      "підтримки --\n",
      "влади --\n",
      "реконструкція --\n",
      "набирає --\n",
      "обертів --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "« --\n",
      "Ще --\n",
      "недавно --\n",
      "велотрек --\n",
      "існував --\n",
      "тільки --\n",
      "у --\n",
      "мріях --\n",
      "ентузіастів --\n",
      "велоруху --\n",
      ", --\n",
      "а --\n",
      "вже --\n",
      "зараз --\n",
      "він --\n",
      "стрімко --\n",
      "набирає --\n",
      "реалістичних --\n",
      "контурів --\n",
      ", --\n",
      "— --\n",
      "радіє --\n",
      "голова --\n",
      "Шевченківської B-ORG\n",
      "райдержадміністрації I-ORG\n",
      "Олег B-PERS\n",
      "Гаряга I-PERS\n",
      ". --\n",
      "— --\n",
      "Ми --\n",
      "сподіваємося --\n",
      ", --\n",
      "що --\n",
      "вже --\n",
      "за --\n",
      "півтора-два --\n",
      "місяці --\n",
      "на --\n",
      "велотреку --\n",
      "зможуть --\n",
      "тренуватися --\n",
      "спортсмени --\n",
      ", --\n",
      "а --\n",
      "проводити --\n",
      "змагання --\n",
      "тут --\n",
      "можна --\n",
      "буде --\n",
      "вже --\n",
      "з --\n",
      "наступної --\n",
      "весни --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "Роботи --\n",
      "на --\n",
      "самому --\n",
      "велотреку --\n",
      "виконуються --\n",
      "за --\n",
      "кошти --\n",
      "меценатів --\n",
      ", --\n",
      "і --\n",
      "я --\n",
      "вдячний --\n",
      "усім --\n",
      "небайдужим --\n",
      ", --\n",
      "хто --\n",
      "сприяє --\n",
      "розвитку --\n",
      "цього --\n",
      "проекту --\n",
      "і --\n",
      "своїми --\n",
      "діями --\n",
      ", --\n",
      "щоденною --\n",
      "працею --\n",
      ", --\n",
      "а --\n",
      "не --\n",
      "галасуванням --\n",
      ", --\n",
      "наближає --\n",
      "його --\n",
      "втілення --\n",
      "» --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "БУЛО --\n",
      "І --\n",
      "Є --\n",
      "</S> --\n",
      "<S> --\n",
      "У --\n",
      "1991-му --\n",
      "цей --\n",
      "об’єкт --\n",
      "був --\n",
      "реконструйований --\n",
      "і --\n",
      "в --\n",
      "1998 --\n",
      "році --\n",
      "внесений --\n",
      "до --\n",
      "переліку --\n",
      "пам’яток --\n",
      "історії --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "А --\n",
      "у --\n",
      "2006-му --\n",
      "цей --\n",
      "майданчик --\n",
      "продали --\n",
      ", --\n",
      "незважаючи --\n",
      "на --\n",
      "протести --\n",
      "громадськості --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "Захищати --\n",
      "велотрек --\n",
      "виходили --\n",
      "сотні --\n",
      "киян --\n",
      ", --\n",
      "і --\n",
      "це --\n",
      "були --\n",
      "фактично --\n",
      "перші --\n",
      "масові --\n",
      "протести --\n",
      "городян --\n",
      "проти --\n",
      "свавілля --\n",
      "забудовників --\n",
      "у --\n",
      "столиці --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "Поряд --\n",
      "побудували --\n",
      "висотку --\n",
      ", --\n",
      "яку --\n",
      "досі --\n",
      "не --\n",
      "можуть --\n",
      "ввести --\n",
      "в --\n",
      "експлуатацію --\n",
      ", --\n",
      "а --\n",
      "на --\n",
      "місці --\n",
      "чаші --\n",
      "велотреку --\n",
      "забудовник --\n",
      "планував --\n",
      "звести --\n",
      "офісний --\n",
      "центр --\n",
      "із --\n",
      "підземним --\n",
      "паркінгом --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "Питання --\n",
      "повернення --\n",
      "міського B-ORG\n",
      "велотреку I-ORG\n",
      "для --\n",
      "киян --\n",
      ", --\n",
      "і --\n",
      "особливо --\n",
      "шевченківців --\n",
      ", --\n",
      "було --\n",
      "принциповим --\n",
      ". --\n",
      "</S> --\n",
      "<S> --\n",
      "У --\n",
      "листопаді --\n",
      "минулого --\n",
      "року --\n",
      "столична --\n",
      "влада --\n",
      "повернула --\n",
      "Київський B-ORG\n",
      "велотрек I-ORG\n",
      "у --\n",
      "власність --\n",
      "громади --\n",
      "міста --\n",
      "— --\n",
      "депутати --\n",
      "Київради B-ORG\n",
      "проголосували --\n",
      "за --\n",
      "розірвання --\n",
      "договору --\n",
      "оренди --\n",
      "земельної --\n",
      "ділянки --\n",
      ", --\n",
      "укладеного --\n",
      "між --\n",
      "Київрадою B-ORG\n",
      "та --\n",
      "підприємством --\n",
      "« --\n",
      "Велотрек B-ORG\n",
      "Авангард I-ORG\n",
      "» --\n",
      ", --\n",
      "на --\n",
      "якій --\n",
      "розташовується --\n",
      "велотрек --\n",
      ". --\n",
      "</S> --\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(tokens, labels):\n",
    "    print(i[0], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of files for training and testing\n",
    "\n",
    "dev_test = {\"dev\": [], \"test\": []}\n",
    "category = \"\"\n",
    "with open(PATH + \"doc/dev-test-split.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line in [\"DEV\", \"TEST\"]:\n",
    "            category = line.lower()\n",
    "        elif len(line) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            dev_test[category].append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 73\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_test[\"dev\"]), len(dev_test[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data and labels\n",
    "\n",
    "train_tokens, test_tokens, train_labels, test_labels = [], [], [], []\n",
    "\n",
    "for filename in dev_test[\"dev\"]:\n",
    "    try:\n",
    "        tokens = read_tokens(PATH + \"data/\" + filename + \".txt\")\n",
    "        train_tokens += [token[0] for token in tokens]\n",
    "        train_labels += extract_labels(read_annotations(PATH + \"data/\" + filename + \".ann\"), tokens)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for filename in dev_test[\"test\"]:\n",
    "    try:\n",
    "        tokens = read_tokens(PATH + \"data/\" + filename + \".txt\")\n",
    "        test_tokens += [token[0] for token in tokens]\n",
    "        test_labels += extract_labels(read_annotations(PATH + \"data/\" + filename + \".ann\"), tokens)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_uk = BPEmb(lang=\"uk\", dim=100)\n",
    "\n",
    "def calc_emb(text):\n",
    "    res = np.zeros(bpemb_uk.vectors.shape[1], dtype=np.float32)\n",
    "    # tokens = word_tokenize(text)\n",
    "    # for t in tokens:\n",
    "    embs = bpemb_uk.embed(text)\n",
    "    for e in embs:\n",
    "        res += e\n",
    "    n = len(embs)\n",
    "    if n:\n",
    "        res /= n\n",
    "    return res/2\n",
    "\n",
    "def word2features(tokens, labels, i):\n",
    "    word = tokens[i]\n",
    "    # print(word)\n",
    "    emb = calc_emb(word)\n",
    "    emb_features = {f'e{k}':v for k, v in enumerate(emb)}\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[:-3]': word[:-3],\n",
    "        'word[:-2]': word[:-2],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    features.update(emb_features)\n",
    "    if i > 0 and tokens[i-1]!='<S>':\n",
    "        word1 = tokens[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:label': labels[i-1]\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        features['-1:label']='--'\n",
    "\n",
    "    if i < len(tokens)-1 and tokens[i+1]!='</S>':\n",
    "        word1 = tokens[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def tokens2features(tokens, labels):\n",
    "    return [word2features(tokens, labels, i) for i in range(len(tokens))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': '<s>',\n",
       "  'word[-3:]': '<S>',\n",
       "  'word[-2:]': 'S>',\n",
       "  'word[:-3]': '',\n",
       "  'word[:-2]': '<',\n",
       "  'word.isupper()': True,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'e0': -0.0543355,\n",
       "  'e1': -0.008262873,\n",
       "  'e2': -0.02015675,\n",
       "  'e3': 0.52813,\n",
       "  'e4': -0.110075496,\n",
       "  'e5': 0.16179413,\n",
       "  'e6': -0.20637862,\n",
       "  'e7': 0.159389,\n",
       "  'e8': -0.12975438,\n",
       "  'e9': -0.25378686,\n",
       "  'e10': 0.020147,\n",
       "  'e11': -0.1470885,\n",
       "  'e12': -0.27274477,\n",
       "  'e13': 0.05038088,\n",
       "  'e14': 0.08779538,\n",
       "  'e15': 0.008998124,\n",
       "  'e16': -0.029331502,\n",
       "  'e17': -0.0527675,\n",
       "  'e18': 0.25626475,\n",
       "  'e19': 0.24143575,\n",
       "  'e20': -0.0420335,\n",
       "  'e21': -0.017392876,\n",
       "  'e22': -0.08190449,\n",
       "  'e23': -0.124100626,\n",
       "  'e24': 0.5533871,\n",
       "  'e25': 0.09283838,\n",
       "  'e26': -0.047879875,\n",
       "  'e27': 0.19545375,\n",
       "  'e28': 0.51434577,\n",
       "  'e29': -0.18040174,\n",
       "  'e30': -0.057013124,\n",
       "  'e31': -0.15036026,\n",
       "  'e32': 0.101021625,\n",
       "  'e33': 0.17088664,\n",
       "  'e34': 0.15010987,\n",
       "  'e35': 0.022323627,\n",
       "  'e36': -0.363561,\n",
       "  'e37': -0.18860963,\n",
       "  'e38': 0.38022035,\n",
       "  'e39': 0.2524385,\n",
       "  'e40': 0.00423075,\n",
       "  'e41': 0.17348063,\n",
       "  'e42': -0.0030456258,\n",
       "  'e43': 0.26807374,\n",
       "  'e44': 0.139282,\n",
       "  'e45': 0.20173325,\n",
       "  'e46': 0.04129025,\n",
       "  'e47': -0.03135225,\n",
       "  'e48': 0.7770804,\n",
       "  'e49': -0.13404025,\n",
       "  'e50': 0.3835966,\n",
       "  'e51': -0.32119012,\n",
       "  'e52': 0.009480375,\n",
       "  'e53': -0.3359841,\n",
       "  'e54': 0.52175725,\n",
       "  'e55': -0.34856373,\n",
       "  'e56': -0.12083024,\n",
       "  'e57': -0.053331506,\n",
       "  'e58': 0.03514275,\n",
       "  'e59': 0.4304005,\n",
       "  'e60': -0.0288715,\n",
       "  'e61': -0.065009624,\n",
       "  'e62': 0.12188563,\n",
       "  'e63': 0.07387225,\n",
       "  'e64': 0.16346088,\n",
       "  'e65': -0.043305002,\n",
       "  'e66': -0.081877,\n",
       "  'e67': -0.28661275,\n",
       "  'e68': 0.01930325,\n",
       "  'e69': -0.03962975,\n",
       "  'e70': 0.09830025,\n",
       "  'e71': -0.060444504,\n",
       "  'e72': 0.07468487,\n",
       "  'e73': -0.09405799,\n",
       "  'e74': -0.011195749,\n",
       "  'e75': -0.16267374,\n",
       "  'e76': 0.15843199,\n",
       "  'e77': -0.10678512,\n",
       "  'e78': -0.08761437,\n",
       "  'e79': -0.1516985,\n",
       "  'e80': -0.15511724,\n",
       "  'e81': 0.050763503,\n",
       "  'e82': 0.057275373,\n",
       "  'e83': -0.056352377,\n",
       "  'e84': 0.036149498,\n",
       "  'e85': -0.071889,\n",
       "  'e86': -0.062048,\n",
       "  'e87': 0.04311025,\n",
       "  'e88': -0.111911505,\n",
       "  'e89': 0.24022123,\n",
       "  'e90': 0.0233055,\n",
       "  'e91': 0.05700288,\n",
       "  'e92': -0.1707725,\n",
       "  'e93': -0.37823,\n",
       "  'e94': -0.09222138,\n",
       "  'e95': -0.19128975,\n",
       "  'e96': 0.022716127,\n",
       "  'e97': 0.22724113,\n",
       "  'e98': -0.020730998,\n",
       "  'e99': 0.011344,\n",
       "  'BOS': True,\n",
       "  '-1:label': '--',\n",
       "  '+1:word.lower()': 'на',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'на',\n",
       "  'word[-3:]': 'На',\n",
       "  'word[-2:]': 'На',\n",
       "  'word[:-3]': '',\n",
       "  'word[:-2]': '',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'e0': -0.1317505,\n",
       "  'e1': 0.0102135,\n",
       "  'e2': -0.0752845,\n",
       "  'e3': -0.3815085,\n",
       "  'e4': 0.20297,\n",
       "  'e5': 0.191354,\n",
       "  'e6': 0.0769755,\n",
       "  'e7': -0.0181755,\n",
       "  'e8': 0.0196015,\n",
       "  'e9': -0.041304,\n",
       "  'e10': 0.253203,\n",
       "  'e11': 0.1552085,\n",
       "  'e12': -0.199439,\n",
       "  'e13': -0.055861,\n",
       "  'e14': 0.1505195,\n",
       "  'e15': -0.069791,\n",
       "  'e16': 0.016918,\n",
       "  'e17': -0.0239125,\n",
       "  'e18': -0.054961,\n",
       "  'e19': 0.050853,\n",
       "  'e20': -0.0283025,\n",
       "  'e21': -0.22356,\n",
       "  'e22': 0.071787,\n",
       "  'e23': 0.042906,\n",
       "  'e24': -0.112623,\n",
       "  'e25': 0.061677,\n",
       "  'e26': -0.07906,\n",
       "  'e27': -0.091598,\n",
       "  'e28': 0.010892,\n",
       "  'e29': -0.065419,\n",
       "  'e30': 0.0977545,\n",
       "  'e31': -0.1258405,\n",
       "  'e32': 0.301104,\n",
       "  'e33': -0.115173,\n",
       "  'e34': 0.1399345,\n",
       "  'e35': 0.11554,\n",
       "  'e36': 0.0132085,\n",
       "  'e37': -0.328287,\n",
       "  'e38': 0.003019,\n",
       "  'e39': 0.2455885,\n",
       "  'e40': -0.1494515,\n",
       "  'e41': -0.068592,\n",
       "  'e42': 0.016054,\n",
       "  'e43': 0.0381085,\n",
       "  'e44': -0.0552985,\n",
       "  'e45': 0.0029375,\n",
       "  'e46': 0.1164285,\n",
       "  'e47': -0.040358,\n",
       "  'e48': 0.0507275,\n",
       "  'e49': 0.0843,\n",
       "  'e50': -0.127546,\n",
       "  'e51': 0.1405555,\n",
       "  'e52': 0.0499175,\n",
       "  'e53': 0.1729785,\n",
       "  'e54': -0.227308,\n",
       "  'e55': 0.0437855,\n",
       "  'e56': -0.022743,\n",
       "  'e57': 0.000615,\n",
       "  'e58': 0.1190395,\n",
       "  'e59': 0.0205255,\n",
       "  'e60': -0.060725,\n",
       "  'e61': 0.248284,\n",
       "  'e62': -0.0644705,\n",
       "  'e63': 0.058069,\n",
       "  'e64': 0.002873,\n",
       "  'e65': 0.311479,\n",
       "  'e66': -0.0724935,\n",
       "  'e67': -0.146207,\n",
       "  'e68': -0.0102,\n",
       "  'e69': 0.08242,\n",
       "  'e70': -0.0789775,\n",
       "  'e71': -0.170831,\n",
       "  'e72': -0.0327725,\n",
       "  'e73': -0.1857915,\n",
       "  'e74': 0.0401655,\n",
       "  'e75': 0.245242,\n",
       "  'e76': 0.061199,\n",
       "  'e77': 0.0573745,\n",
       "  'e78': 0.1019275,\n",
       "  'e79': 0.1527105,\n",
       "  'e80': -0.1111155,\n",
       "  'e81': -0.050846,\n",
       "  'e82': -0.1417165,\n",
       "  'e83': 0.269386,\n",
       "  'e84': -0.066459,\n",
       "  'e85': 0.006562,\n",
       "  'e86': 0.065231,\n",
       "  'e87': 0.1596865,\n",
       "  'e88': -0.108623,\n",
       "  'e89': 0.094915,\n",
       "  'e90': -0.059351,\n",
       "  'e91': -0.0389425,\n",
       "  'e92': -0.231611,\n",
       "  'e93': -0.1165355,\n",
       "  'e94': -0.126408,\n",
       "  'e95': 0.268623,\n",
       "  'e96': 0.1310165,\n",
       "  'e97': -0.1144255,\n",
       "  'e98': 0.1192295,\n",
       "  'e99': -0.0756925,\n",
       "  'BOS': True,\n",
       "  '-1:label': '--',\n",
       "  '+1:word.lower()': 'довірливих',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'довірливих',\n",
       "  'word[-3:]': 'вих',\n",
       "  'word[-2:]': 'их',\n",
       "  'word[:-3]': 'довірли',\n",
       "  'word[:-2]': 'довірлив',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'e0': 0.13178833,\n",
       "  'e1': 0.10236317,\n",
       "  'e2': 0.09019983,\n",
       "  'e3': 0.019650498,\n",
       "  'e4': -0.016069164,\n",
       "  'e5': 0.06035367,\n",
       "  'e6': -0.196669,\n",
       "  'e7': -0.10815016,\n",
       "  'e8': -0.069848835,\n",
       "  'e9': 0.055861663,\n",
       "  'e10': -0.116856,\n",
       "  'e11': 0.050756503,\n",
       "  'e12': 0.10354916,\n",
       "  'e13': -0.1836495,\n",
       "  'e14': 0.037084665,\n",
       "  'e15': 0.07373116,\n",
       "  'e16': -0.037894,\n",
       "  'e17': -0.0311265,\n",
       "  'e18': 0.037188668,\n",
       "  'e19': 0.049211,\n",
       "  'e20': -0.03874017,\n",
       "  'e21': -0.055859834,\n",
       "  'e22': -0.030245999,\n",
       "  'e23': 0.00058649975,\n",
       "  'e24': 0.23687834,\n",
       "  'e25': 0.036248833,\n",
       "  'e26': 0.06873467,\n",
       "  'e27': 0.032843832,\n",
       "  'e28': -0.1285015,\n",
       "  'e29': -0.0273235,\n",
       "  'e30': 0.18931365,\n",
       "  'e31': -0.028088832,\n",
       "  'e32': -0.22445883,\n",
       "  'e33': -0.1986055,\n",
       "  'e34': 0.20209266,\n",
       "  'e35': 0.14001201,\n",
       "  'e36': 0.16028933,\n",
       "  'e37': 0.015618333,\n",
       "  'e38': -0.15271483,\n",
       "  'e39': -0.048286002,\n",
       "  'e40': 0.049423162,\n",
       "  'e41': 0.015558,\n",
       "  'e42': -0.22641416,\n",
       "  'e43': -0.12903117,\n",
       "  'e44': -0.2383305,\n",
       "  'e45': -0.0983695,\n",
       "  'e46': 0.38472685,\n",
       "  'e47': -0.11440149,\n",
       "  'e48': 0.10744199,\n",
       "  'e49': 0.05197883,\n",
       "  'e50': -0.25715283,\n",
       "  'e51': -0.013301496,\n",
       "  'e52': -0.18360667,\n",
       "  'e53': 0.010673165,\n",
       "  'e54': 0.13226883,\n",
       "  'e55': -0.05797166,\n",
       "  'e56': -0.12013483,\n",
       "  'e57': -0.06877083,\n",
       "  'e58': -0.16302784,\n",
       "  'e59': 0.037105333,\n",
       "  'e60': -0.08174566,\n",
       "  'e61': 0.017681668,\n",
       "  'e62': -0.26797783,\n",
       "  'e63': -0.122050665,\n",
       "  'e64': -0.118115,\n",
       "  'e65': 0.042793006,\n",
       "  'e66': -0.03381417,\n",
       "  'e67': 0.04724783,\n",
       "  'e68': 0.24721582,\n",
       "  'e69': -0.019848997,\n",
       "  'e70': 0.20822716,\n",
       "  'e71': -0.113373496,\n",
       "  'e72': 0.06528018,\n",
       "  'e73': -0.025675168,\n",
       "  'e74': -0.115036,\n",
       "  'e75': -0.12102934,\n",
       "  'e76': 0.1252725,\n",
       "  'e77': -0.39347067,\n",
       "  'e78': 0.031741504,\n",
       "  'e79': 0.067652665,\n",
       "  'e80': -0.158423,\n",
       "  'e81': -0.021230996,\n",
       "  'e82': -0.080049165,\n",
       "  'e83': -0.15504867,\n",
       "  'e84': -0.086545,\n",
       "  'e85': -0.060166165,\n",
       "  'e86': -0.057487,\n",
       "  'e87': 0.054876,\n",
       "  'e88': -0.20378768,\n",
       "  'e89': 0.07569499,\n",
       "  'e90': -0.15607299,\n",
       "  'e91': -0.16667767,\n",
       "  'e92': 0.0038183331,\n",
       "  'e93': 0.23138982,\n",
       "  'e94': -0.059193164,\n",
       "  'e95': -0.130741,\n",
       "  'e96': 0.10400033,\n",
       "  'e97': -0.15998334,\n",
       "  'e98': -0.294531,\n",
       "  'e99': 0.027290002,\n",
       "  '-1:word.lower()': 'на',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:label': '--',\n",
       "  '+1:word.lower()': 'кіровоградців',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb = calc_emb('слово')\n",
    "# print(emb)\n",
    "# emb_features = {f'e{k}':v for k, v in enumerate(emb)}\n",
    "\n",
    "tokens2features(train_tokens, train_labels)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [tokens2features(train_tokens, train_labels)]\n",
    "y_train = [train_labels]\n",
    "\n",
    "X_test = [tokens2features(test_tokens, test_labels)]\n",
    "y_test = [test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loading training data to CRFsuite:   0%|                                                         | 0/1 [00:00<?, ?it/s]\n",
      "loading training data to CRFsuite: 100%|█████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 170557\n",
      "Seconds required: 2.103\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.95  loss=129219.47 active=170101 feature_norm=1.00\n",
      "Iter 2   time=0.47  loss=67071.64 active=167717 feature_norm=2.79\n",
      "Iter 3   time=0.47  loss=60852.87 active=165278 feature_norm=2.61\n",
      "Iter 4   time=0.94  loss=56899.13 active=141578 feature_norm=2.16\n",
      "Iter 5   time=0.48  loss=41842.70 active=168989 feature_norm=2.63\n",
      "Iter 6   time=0.49  loss=37949.61 active=169276 feature_norm=2.78\n",
      "Iter 7   time=0.50  loss=33214.17 active=101610 feature_norm=3.46\n",
      "Iter 8   time=0.49  loss=29949.10 active=87359 feature_norm=3.91\n",
      "Iter 9   time=0.48  loss=22530.82 active=83521 feature_norm=5.31\n",
      "Iter 10  time=0.48  loss=17547.95 active=79788 feature_norm=6.87\n",
      "Iter 11  time=0.49  loss=14865.24 active=72259 feature_norm=8.40\n",
      "Iter 12  time=0.48  loss=13477.40 active=71065 feature_norm=9.04\n",
      "Iter 13  time=0.49  loss=12092.78 active=69249 feature_norm=10.24\n",
      "Iter 14  time=0.49  loss=10138.14 active=61898 feature_norm=12.20\n",
      "Iter 15  time=0.49  loss=8840.65  active=58638 feature_norm=14.58\n",
      "Iter 16  time=0.49  loss=8147.80  active=56911 feature_norm=15.30\n",
      "Iter 17  time=0.49  loss=7276.86  active=54102 feature_norm=16.85\n",
      "Iter 18  time=0.48  loss=6394.03  active=50032 feature_norm=19.21\n",
      "Iter 19  time=0.50  loss=5960.95  active=48490 feature_norm=21.17\n",
      "Iter 20  time=0.49  loss=5602.64  active=47692 feature_norm=22.09\n",
      "Iter 21  time=0.49  loss=5310.48  active=46294 feature_norm=23.42\n",
      "Iter 22  time=0.49  loss=4880.21  active=43964 feature_norm=25.68\n",
      "Iter 23  time=0.50  loss=4599.27  active=42280 feature_norm=28.58\n",
      "Iter 24  time=0.49  loss=4318.99  active=40187 feature_norm=30.19\n",
      "Iter 25  time=0.49  loss=4064.44  active=37717 feature_norm=32.44\n",
      "Iter 26  time=0.48  loss=3677.42  active=35407 feature_norm=36.37\n",
      "Iter 27  time=0.50  loss=3354.53  active=34196 feature_norm=40.05\n",
      "Iter 28  time=0.49  loss=3097.93  active=33091 feature_norm=43.26\n",
      "Iter 29  time=0.49  loss=2837.75  active=31683 feature_norm=47.43\n",
      "Iter 30  time=0.49  loss=2633.00  active=30104 feature_norm=50.78\n",
      "Iter 31  time=0.50  loss=2458.91  active=28262 feature_norm=54.02\n",
      "Iter 32  time=0.49  loss=2313.18  active=26325 feature_norm=57.16\n",
      "Iter 33  time=0.48  loss=2261.12  active=24447 feature_norm=60.90\n",
      "Iter 34  time=0.48  loss=2135.86  active=24196 feature_norm=61.59\n",
      "Iter 35  time=0.49  loss=2096.74  active=23763 feature_norm=62.37\n",
      "Iter 36  time=0.49  loss=2037.92  active=22912 feature_norm=63.80\n",
      "Iter 37  time=0.50  loss=1986.22  active=21755 feature_norm=64.91\n",
      "Iter 38  time=0.49  loss=1936.77  active=21390 feature_norm=65.58\n",
      "Iter 39  time=0.50  loss=1906.76  active=20659 feature_norm=65.89\n",
      "Iter 40  time=0.51  loss=1881.34  active=19799 feature_norm=66.24\n",
      "Iter 41  time=0.49  loss=1863.41  active=19313 feature_norm=66.37\n",
      "Iter 42  time=0.48  loss=1852.49  active=19099 feature_norm=66.46\n",
      "Iter 43  time=0.48  loss=1830.63  active=18068 feature_norm=66.76\n",
      "Iter 44  time=0.97  loss=1828.69  active=17237 feature_norm=67.70\n",
      "Iter 45  time=0.49  loss=1803.85  active=17125 feature_norm=67.93\n",
      "Iter 46  time=0.49  loss=1796.10  active=16902 feature_norm=68.21\n",
      "Iter 47  time=0.50  loss=1788.37  active=16603 feature_norm=68.56\n",
      "Iter 48  time=0.49  loss=1776.44  active=16507 feature_norm=68.91\n",
      "Iter 49  time=0.48  loss=1771.00  active=16328 feature_norm=69.13\n",
      "Iter 50  time=0.49  loss=1763.09  active=16139 feature_norm=69.49\n",
      "Iter 51  time=0.49  loss=1757.37  active=15942 feature_norm=69.65\n",
      "Iter 52  time=0.49  loss=1752.36  active=15792 feature_norm=69.90\n",
      "Iter 53  time=0.49  loss=1747.91  active=15642 feature_norm=70.00\n",
      "Iter 54  time=0.49  loss=1743.90  active=15478 feature_norm=70.22\n",
      "Iter 55  time=0.49  loss=1739.69  active=15275 feature_norm=70.33\n",
      "Iter 56  time=0.49  loss=1736.04  active=15150 feature_norm=70.51\n",
      "Iter 57  time=0.48  loss=1732.94  active=14991 feature_norm=70.59\n",
      "Iter 58  time=0.49  loss=1730.11  active=14844 feature_norm=70.71\n",
      "Iter 59  time=0.49  loss=1727.45  active=14708 feature_norm=70.76\n",
      "Iter 60  time=0.49  loss=1725.34  active=14592 feature_norm=70.86\n",
      "Iter 61  time=0.50  loss=1722.62  active=14461 feature_norm=70.89\n",
      "Iter 62  time=0.48  loss=1720.89  active=14346 feature_norm=70.99\n",
      "Iter 63  time=0.49  loss=1718.09  active=14220 feature_norm=71.03\n",
      "Iter 64  time=0.49  loss=1716.44  active=14128 feature_norm=71.12\n",
      "Iter 65  time=0.48  loss=1713.85  active=13999 feature_norm=71.15\n",
      "Iter 66  time=0.49  loss=1712.57  active=13914 feature_norm=71.24\n",
      "Iter 67  time=0.50  loss=1710.18  active=13828 feature_norm=71.28\n",
      "Iter 68  time=0.49  loss=1709.23  active=13761 feature_norm=71.36\n",
      "Iter 69  time=0.49  loss=1706.97  active=13711 feature_norm=71.40\n",
      "Iter 70  time=0.49  loss=1706.10  active=13661 feature_norm=71.46\n",
      "Iter 71  time=0.50  loss=1704.13  active=13618 feature_norm=71.50\n",
      "Iter 72  time=0.48  loss=1703.49  active=13582 feature_norm=71.56\n",
      "Iter 73  time=0.49  loss=1701.67  active=13540 feature_norm=71.60\n",
      "Iter 74  time=0.49  loss=1701.22  active=13524 feature_norm=71.66\n",
      "Iter 75  time=0.50  loss=1699.36  active=13482 feature_norm=71.69\n",
      "Iter 76  time=0.49  loss=1698.76  active=13412 feature_norm=71.74\n",
      "Iter 77  time=0.50  loss=1697.11  active=13347 feature_norm=71.77\n",
      "Iter 78  time=0.49  loss=1696.80  active=13307 feature_norm=71.83\n",
      "Iter 79  time=0.49  loss=1694.82  active=13267 feature_norm=71.85\n",
      "Iter 80  time=0.48  loss=1694.26  active=13239 feature_norm=71.90\n",
      "Iter 81  time=0.48  loss=1692.72  active=13171 feature_norm=71.91\n",
      "Iter 82  time=0.49  loss=1692.63  active=13111 feature_norm=71.97\n",
      "Iter 83  time=0.49  loss=1690.43  active=13056 feature_norm=71.98\n",
      "Iter 84  time=0.49  loss=1690.13  active=13001 feature_norm=72.03\n",
      "Iter 85  time=0.49  loss=1688.36  active=12966 feature_norm=72.04\n",
      "Iter 86  time=0.97  loss=1687.57  active=12952 feature_norm=72.06\n",
      "Iter 87  time=0.49  loss=1686.60  active=12885 feature_norm=72.05\n",
      "Iter 88  time=0.48  loss=1686.03  active=12854 feature_norm=72.09\n",
      "Iter 89  time=0.49  loss=1684.28  active=12805 feature_norm=72.07\n",
      "Iter 90  time=0.49  loss=1683.60  active=12777 feature_norm=72.10\n",
      "Iter 91  time=0.49  loss=1682.01  active=12750 feature_norm=72.08\n",
      "Iter 92  time=0.49  loss=1681.03  active=12739 feature_norm=72.08\n",
      "Iter 93  time=0.49  loss=1680.27  active=12695 feature_norm=72.04\n",
      "Iter 94  time=0.49  loss=1679.53  active=12644 feature_norm=72.03\n",
      "Iter 95  time=0.48  loss=1678.22  active=12612 feature_norm=71.98\n",
      "Iter 96  time=0.48  loss=1677.58  active=12617 feature_norm=71.98\n",
      "Iter 97  time=0.49  loss=1676.34  active=12578 feature_norm=71.92\n",
      "Iter 98  time=0.49  loss=1675.74  active=12549 feature_norm=71.91\n",
      "Iter 99  time=0.49  loss=1674.50  active=12508 feature_norm=71.86\n",
      "Iter 100 time=0.50  loss=1673.96  active=12488 feature_norm=71.86\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 50.869\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 12488 (170557)\n",
      "Number of active attributes: 8717 (149702)\n",
      "Number of active labels: 9 (9)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.028\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=1\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-PERS', 'I-PERS']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('--')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587335120376974"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.873     0.751     0.807       413\n",
      "       I-LOC      0.968     0.784     0.866      1071\n",
      "      B-MISC      0.617     0.568     0.592       176\n",
      "      I-MISC      0.834     0.949     0.888       375\n",
      "       B-ORG      0.576     0.518     0.545       228\n",
      "       I-ORG      0.987     0.603     0.748      1954\n",
      "      B-PERS      0.864     0.835     0.849      1155\n",
      "      I-PERS      0.980     0.986     0.983      2795\n",
      "\n",
      "   micro avg      0.928     0.811     0.865      8167\n",
      "   macro avg      0.837     0.749     0.785      8167\n",
      "weighted avg      0.932     0.811     0.859      8167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
